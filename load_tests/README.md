# Kokoro TTS Load Testing

This directory contains load testing configuration for the Kokoro TTS API using Locust.

## Setup

1. First, ensure the main Kokoro TTS service is running and healthy:
```bash
# From the root directory
docker compose up -d kokoro-tts
docker compose ps  # Wait until kokoro-tts is healthy
```

2. Then start the Locust service:
```bash
cd load_tests
docker compose up -d
```

3. Access the Locust web interface at http://localhost:8089

Note: The load tests require the main service to be running and healthy first, as they connect to it over a shared Docker network.

## Test Scenarios

The load tests focus on streaming responses with varied text lengths using natural language phrases:

- Short texts (50-200 chars) - highest frequency (3x weight)
- Medium texts (200-500 chars) - medium frequency (2x weight)
- Long texts (500-1000 chars) - lower frequency (1x weight)
- Periodic voice listing calls (1x weight)

### Text Generation

Test data is generated by combining phrases from `sample_data/phrases.json` to create natural-sounding text of varying lengths. This provides more realistic test scenarios compared to random character generation.

## Running Tests

1. Enter the desired number of users and spawn rate in the web interface
2. Click "Start swarming" to begin the test
3. Monitor real-time metrics and test results through the interface

## Key Metrics

### Metrics Tracked

- Time to First Chunk: Latency until first audio data arrives
- Total Response Time: Complete request duration
- Success/Failure Rates: Per request type
- Request Rate (RPS): Overall throughput
- Response Time Percentiles: 50th, 95th, 99th percentiles
- Error Rates: Broken down by request type and length

### Test Types

1. Streaming Requests:
   - Short (50-200 chars) - 3x frequency
   - Medium (200-500 chars) - 2x frequency
   - Long (500-1000 chars) - 1x frequency

2. Non-Streaming Requests:
   - Short texts only (50-200 chars) - 2x frequency
   - Full response timing

3. API Health:
   - Voice listing calls - 1x frequency

## Notes

- Tests automatically fetch available voices on startup
- Natural phrases are combined to reach target lengths
- Realistic wait times between requests (1-3 seconds)
- All audio requests use streaming mode
- Tests run against the OpenAI-compatible endpoint
